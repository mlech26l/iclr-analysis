{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "Summary: This paper proposes a unified model for continual learning and aims to address the following problems:\nOut-of-train-domain dataset recognition\nCatastrophic forgetting\nThe out-of-domain or open set recognition model is not only used to detect outliers but also for sampling \u201crepresentative data\u201d of previous tasks for forward (and backward) transfer. \n\nCOMMENT(S)/QUERIES:\n------------------------------\n \nWhile the experiments do justice to the contributions mentioned in the paper, I believe that certain sections need clarifications and expansion (while some can be dismissed). \n\n1. Given my limited knowledge in the literature on this topic, I would have appreciated a proper related work section. \n\n2. I believe equation (1) could have been moved to supplementary for reference since equation (2) is the only important equation in the paper. \nI don\u2019t believe Equation (1) is really used for testing purposes. It\u2019s just that the data is sent through the probabilistic encoder and then classified. There is no need for reconstruction of the data point.\n\n3. It\u2019s difficult to follow the flow of the method. Shouldn\u2019t generative replay (algorithm 3) be placed before open set recognition of unknown and uncertain inputs (algorithm 2), since the latter is probably just used during the test, while the former affects the training procedure directly (implicit data augmentation)?\n\n4. Major concern: It\u2019s somewhat strange to observe that the VAE model is able to generate multiclass data so fluidly with a simple gaussian prior. This kind of challenges the belief that current generative models are unable to capture all modes perfectly. A small note about why multimodal prior was not used (which intuitively and mathematically makes more sense) and also a statement about the average time to generate multiclass multi-modal data using algorithm 3 would have been nice. \n\n5. In section 3.2, \u201cFor our single-head expanding classifier this ensures..\u201d. While having a single-head expanding classifier is listed as one of the important contributions, it hasn\u2019t been given enough justice w.r.t to the implementation details. Is it like adding a completely new classifier during the training of the new task?\nThe entire section on hyper-parameters could\u2019ve been moved to the supplementary if space was a major constraint but compromising on details about an important contribution only weakens the paper. \n\nI especially like figure 2 in the experiments, where the importance of Weibull CDF outlier rejection prior is highlighted.\n\n\nTypo: \nincorrect opening inverted comma for the word background in the introduction section (page 1)\n\nOVERALL COMMENT\n-----------------------------\n\nThe paper combines the generative, and discriminative models into one framework for multiple important tasks. While the contributions are clear in the introduction, the presentation of the paper is somewhat too complicated at a couple of places. It does not do full justice to explaining its more vital components and some parts of the method section feel like a jigsaw puzzle, where readers are heavily expected to \u201cfigure out on their own\u201d. \nWith proper presentation though, I can envision this paper contributing positively to unified frameworks in general.\n\nDue to the above reasons. I am giving it a score of 6.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}