{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "N/A", "title": "Official Blind Review #1", "review": "This paper studied an interesting question, whether the gain of robustness from synthetic distribution shifts can be transferred/generalized to the robustness under natural distribution shifts. It was shown that in the context of natural distribution shifts, no current robustness intervention can really outperform standard models without a robustness intervention. The main strength of this paper is its extensive experimental study. However, I still have concerns on this work.\n\n1)  The authors mentioned \"an implicit assumption underlying this research direction is that robustness to such synthetic distribution shifts will lead to models that also perform more reliably on natural distribution shifts.\" However, I am uncertain about this point. Let us take adversarial robustness as an example, I am NOT surprising that the robustness on crafted adversarial examples cannot be generalized to the robustness over natural distribution shifts. Thus, I do not think that adversarial robustness obeys the 'implicit assumption'. In other words, the studied problem should be better connected to adversarial robustness.\n\n2) The significance of 'effective robustness' is not clear. It seems that most of insights were learnt from Figure 1, 3 and 4. Do they rely on the metric 'effective robustness'? \n\n3) In Figure 1, 'Trained with more' -> 'Trained with more data'\n\n############# Post-feedback ################\nThanks for the response. I am still not fully convinced by the significance of the findings in this work.\nIn the paper, the authors highlighted that \"our results show that current robustness gains on synthetic distribution shifts do not transfer to improved robustness on the natural distribution shifts presently available as test sets.\"  I am not surprising at this point, since the synthetic shift, e.g., introduced from adversarial examples, may only characterize the short-cut shift for misclassification. Thus, robustness learnt from this synthetic distribution shift might not transfer to the natural distribution shift. \n\nI decide to keep my original score. \n", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}