{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #3", "review": "------------- updated after rebuttal -------------------\n\nI thank the authors for clarifying and correcting the notations in Lemma 3. Though I still think the current state of the derivation is presented in a suboptimal way, and as a result, can be misleading to people.\n\nThe Fourier analysis used to give the results that the exact gradient equals $2\\hat{f}^{(p\\to 1/2)}(i)$ (eq. 5) is totally unnecessary: Despite it might seem fancy as a Fourier coefficient, it is just another way of writing the local expectation estimator (Tokui, S., & Sato, I., 2017), if we expand it using the definition $\\hat{f}^{(p)}(S) = E_{p(z)}[f(z)\\phi_S(z)]$.\n\nThe authors argue that the Fourier analysis is essential to show the bias of the estimator. However, the only conclusion they draw from Fourier analysis is eq.5. And all the bias analysis follows by using Taylor expansions of it. The paper can be greatly simplified if they remove all boolean analysis parts and start from eq. 5 (which has a straightforward proof), using the conventional notation instead of Fourier coefficients. \n\nDuring writing this, I read the bias correction section again and had another concern, the bias correction effect is only justified for functions with small mixed degree terms:\n\n\"For functions with small mixed degree terms, this can lead to bias\nreduction, at the cost of an increased variance because of sampling an auxiliary variable\"\n\nFor general multivariate functions, it is even not clear whether the proposed estimator has a smaller bias than the straight-through one. This weakness has a deep reason behind it because they are trying to generalize a bias reduction technique from a univariate function to multivariate functions, which, if done natively, would require K evaluations of the function (K is the number of input dimensions) (as I pointed out in the original review).\n\nOverall, I argue rejecting the paper in its current form.\n\n----------------------------------------------------------------\n\nThis is not my first time reviewing this paper. Previous concerns on clarity has been addressed and the paper is now more readable. Though I still believe that the boolean analysis part is unnecessary for deriving the final estimator (which can be easily derived from the exact local-expectation estimator E_p[f(z_i=1) - f(z_i=0)] and applying f(1) - f(0) = \\int_0^1 f'(x) dx \\approx f(e), e~Unif[0,1].) plus some importance sampling trick.\n\nI think the proof of Lemma 3 is incorrect (though the conclusion is correct). f is never multi-linear in the continuous space. It is only for the boolean space, that f has an multi-linear form with Fourier expansion. So the claim that f is multi-linear then\n\nE_{p(z}}[f(z_1, ..., z_n)] = f(\\mu_1, ..., \\mu_n)\n\nis incorrect. This can only be true when f is also linear in the continuous space (which is not true for typical vaes).\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}