{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #4", "review": "The paper describes a new neural architecture search method based on monte-carlo tree search that dynamically adapts the action space.\nThe methods consists of two stages. In the first stage, the learning stage, the action space is divided into good and bad regions based on a tree structure. In the seconds stage, new data is generated by sampling new architecture with monte-carlo tree search. Those two stages are iterated with new incoming data.\n\nThe paper proposes an interesting approach which achieves competitive results compared to state-of-the-art methods.\nIn general the paper is well written and easy to follow. However,  I haven't fully understood  how the model space is divided at different nodes. What exactly is the splitting criterium? Are the splits axis aligned?\n\nFurther comments:\n\n- Figure 4 a and b seemed to be flipped?\n\n- Figure 5 top row would be easier to parse if the x-axis is on a log scale.\n\n- Could you also include other Bayesian optimization methods, such as SMAC or TPE, which should competitive performance on NASBench101 and do not suffer from a cubic scaling\n\n\n\npost rebuttal\n------------------\n\n\nI thank the authors for performing additional experiments and clarifying my questions. First of all, I would like to stress that I still think the approach seems promising.\nHowever, I am not entirely convinced by the empirical results.  While the proposed method converges faster to the global optimum than other methods, it is only able to improve by a little epsilon in terms of validation accuracy,  which could indicate overfitting on these tabular benchmarks. Furthermore, in the beginning Bayesian optimisation based methods consistently perform better which might be in practice more relevant for these highly expensive optimisation problems.  Because of that, I keep my initial score. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}