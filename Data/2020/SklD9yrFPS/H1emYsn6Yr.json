{"experience_assessment": "I have read many papers in this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "POST-REBUTTAL COMMENTS\n\nI appreciate the response from the authors. \n\nI particularly like the comparison table in the response to the other reviewer and ought to be highlighted in the paper.\n\nIf I were to start this line of research, I would be inclined to expand on the codebase. The contribution is significant. Hence, I am bumping up my score to accept.\n\n\nPRIOR FEEDBACK\n\nThe contribution of this work lies in providing a library for working with the existing variants of infinite-width neural networks and avoiding the need to derive the NNGP and NT kernels for each architecture by hand. The authors have firstly shown performance comparisons between inferences between finite vs. infinitely wide neural networks. The authors then go into some implementation details with their library. The authors have provided the code and cookbook in the links provided in the abstract. On the overall, I like this effort which is timely.\n\nSome additional suggestions below:\n\nI would like to see an additional metric for performance comparison of probabilistic models, which is often used in the GP literature: mean negative log probability.\n\nIt would also be interesting to see how the posterior variance (e.g., Fig. 1 right) evolves over the entire space during training. \n\nI would have preferred a more detailed discussion about the implementation on transforming tensor ops to kernel ops in Section 3.\n\nFor the summary of contributions, can you give the corresponding section number to refer to when you demonstrate each feature? For example, is the 4th feature (i.e., exploring weight space perspective) demonstrated in the paper?\n\nCan the authors elaborate on the ease of expanding their library for the new developments in this field?\n\n\nMinor issues:\n\nPage 1: Gaussian Procesesses?\nPage 4: it\u2019s infinite?\nFig. 4: I would have preferred the indices to be placed as subscripts instead of superscripts.\nPage 8: it\u2019s order of dimensions?", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}