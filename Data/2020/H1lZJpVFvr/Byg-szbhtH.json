{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "N/A", "title": "Official Blind Review #2", "review": "In this paper, the authors proposed a new approach to improve the robustness of CNNs against adversarial examples.\nThe recent studies show that CNNs capture local features, which can be easily affected by the adversarial perturbations.\nThus, in the paper, the authors proposed to train CNNs so that they can capture local features that are robust against the adversarial perturbations.\nThe difficulty here is that existing adversarial training algorithms tend to bias CNNs to ignore local features and to capture only global features.\nTo avoid this unfavorable property of the adversarial training, the authors proposed the random block shuffle (RBS) that intensionally destroys the global feature of the images.\nThe authors demonstrated that combining RBS with the existing adversarial training algorithms can lead to robust CNNs.\n\nI found the paper well-written and the idea is easy to follow.\nEspecially, the use of RBS seems to be an interesting idea.\nAs a small downside, the proposed approach looks rather straightforward, and I expect to see any theoretical foundations if possible.\n\n### Updated after author response ###\nIn summary, the contribution of this study is in twofolds.\n1. Proposed an algorithm for learning robust local features.\n2. Demonstrated that learning robust local features is effective to improve the robustness of the model.\nThe possible downside is\n3. The proposed approach looks straightforward.\nOverall, I like the paper (especially for the reason 2 above), and therefore keep my score.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}