{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #4", "review": "Overall I think there is a room for this paper to improve. I expect to see more comprehensive experiments for comparing Adam and AdamT. The authors applied AdamT to four different tasks and compared training and testing loss difference. Are the models used in these tasks state-of-the-art? I did not see a discussion about whether parameters (including learning rate) are tuned for the best results for each optimization method. Also it is hard to visualize the difference in a figure (e.g. Figure 3) to claim whether it is significant. I would suggest using more quantitative measures.\n\nMore details:\n- label all equations\n- second paragraph on page 3: \"are denoted as \\alpha and \\beta\" --> \\gamma and \\beta?\n- \"Equation 3.1\": which equation?\n- FIg. 1: Has the author tried different learning rates for Adam? I wonder whether the faster convergence speed by the proposed trend estimation can be achieved by a larger learning rate\n- Fig. 3: The testing loss for Adam+Dropout and AdamT+Dropout does not seem to be significant. Is the loss smoothed or averaged across different runs to remove randomness? Can the authors apply AdamT to the state-of-the-art model for CIFAR-10 and can still show advantages?", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}