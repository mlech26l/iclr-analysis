{"experience_assessment": "I have published in this field for several years.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "This paper studies the problem of unsupervised scene decomposition with a foreground-background probabilistic modeling framework. Building upon the idea from the previous work on probabilistic scene decomposition [Crawford & Pineau 2019], this paper further decomposes the scene background into a sequence of background segments. In addition, with the proposed framework, scene foreground-background interactions are decoupled into foreground objects and background segments using chain rules. Experimental evaluations have been conducted on several synthetic datasets including the Atari environments and 3D-Rooms. Results demonstrate that the proposed method is superior to the existing baseline methods in both decomposing objects and background segments.\n\nOverall, this paper studies an interesting problem in deep representation learning applied to scene decomposition. Experimental results demonstrated incremental improvements over the baseline method [Crawford & Pineau 2019] in terms of object detection. However, reviewer has a few questions regarding the intuition behind the foreground-background formulation and the generalization ability to unseen combinations or noisy inputs.\n\n== Qualitative results & generalization ==\nThe qualitative improvements over the baseline method [Crawford & Pineau 2019] seem not very impressive (Figure 1: only works a bit better with cluttered scenes). First, how does the proposed method perform in real world datasets (Outdoor: KITTI, CItyscape; Indoor: ADE20K, MS-COCO)? Second, the generalization to unseen scenarios are mentioned in the introduction but not really carefully studied or evaluated in the experiments. For example, one experiment would be to train the framework on the current 3D-Rooms dataset but then test on new environments (e.g., other room layout) or new objects (e.g. other shapes such as shapenet objects). \n\n\n== Application beyond object detection ==\nEquation (4) does not seem to be natural in practice: basically, the background latents depends on the foreground object latents. Alternatively, you can assume them to be independent with each other. It\u2019s better to clarify this point in the rebuttal. As this is a generative model, reviewer would like to know the applicability to other tasks such as pure generation, denoising and inpainting. For example, how does the pre-trained model perform with noisy input (e.g., white noise added to the image)? Also, what\u2019s the pure generation results following the chain rules given by Equation (1), (3) & (4).\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}