{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "Edit after author rebuttal and author additions:\n\nI have updated my score from a weak reject (3) to a weak accept (6).\n\nJustification:\n\n1. The authors have pointed out that I misunderstood one of their contributions: pointing out that they are demonstrating that the univariate case is an insufficient setting to test causal discovery methods because it can be done without even looking at the conditional distributions (just the marginals). This contribution seems important to orient future work. They have made this more clear in their recent upload and would likely make it even more clear in a camera-ready version.\n\n2. The authors have made their contribution to the multivariate setting more substantial by adding evaluation on the MOUS-MEG real-world dataset and have better positioned their work relative to others by adding comparisions to multivariate extensions of PNL and CGNN.\n\n====================================================================================================\n\nOriginal Review:\n\nSummary: The authors focus on the problem of inferring whether the causal structure X \u2014> Y or Y \u2014> X. They first consider the case where both X and Y are scalar (univariate) random variables and then consider the case where X and Y are vector-valued (multivariate) random variables. In the scalar case, motivated by the idea that the effect could be less entropic than the cause (due to data processing inequality), they introduce a method based on comparing reconstruction losses of X and Y and show competitive results in Tables 1 and 2. They establish that this method is not sufficient for the multivariate case in Lemma 2 and move to a new method for the multivariate case. They prove identifiability for this new method in for the multivariate case in Section 4.2 and claim state-of-the-art (SOTA) results in Table 3.\u2028\n\nMain contributions:\n- Presents a causal discovery technique for the univariate cases that only examines the marginal distributions of X and Y and seems fairly competitive (Tables 1 and 2)\n- Extends the post-nonlinear identifiability analysis of Zhang & Hyv\u00a8arinen (2009) from scalars to vectors and proved that their method will actually identify the correct causal direction\n- Demonstrates competitive experimental results for both their univariate method\n- Claims SOTA results for their multivariate method\n\nDecision: I lean toward rejecting this paper because 1) I have several questions about the univariate case (see below) that would need to be resolved before I lean toward accept, 2) although I am not too familiar with the literature, I believe that this paper may be missing key related work that also uses independence testing for causal discovery (see, e.g., Heinze-Deml et al. (2017)\u2019s Invariant Causal Prediction for Nonlinear Models), and 3) I am not yet convinced that the comparison done in Table 3 is fair and exhaustive.\u2028\u2028\n\nSufficient reason to accept: If the theorems in Section 4.2 are found to checkout, and the SOTA results in Table 3 are found to be fair, exhaustive comparisons to the previous SOTA, their contribution to the multivariate case would seem to be sufficient for acceptance. I believe more discussion between the authors and reviewers is necessary here.\n\n\u2028Questions about univariate case:\n\n\u20281. The motivation for the first method (entropy decreasing along a Markov chain due the data processing inequality) seems to only be valid when Y := f(X), but not necessarily when Y := f(X) + E. For example, let f be the identity function and E be independent to X. How did you resolve this argument against the intuition?\u2028\n\n2. Also, I thought the data processing inequality relates mutual information between variables, not necessarily their entropies. Can you make this connection more clear?\u2028\n\nContext for questions 3 and 4: In Section 3.1, you write, \u201cestimating the entropy of each random variable from its samples does not present a consistent difference between the entropies h(X)  and h(Y). Our method, therefore, computes an alternative complexity score for X and, independently, for Y.\u201d You then go on to link the entropy to the reconstruction error (your method) in Lemma 1 and show competitive results in Tables 1 and 2.\n\n3. Why do you want to link the reconstruction error to entropy if you found a purely entropy-based method did not work?\n\n4. Why did the purely entropy-based method not work while your method worked if the two are linked?\n\nQuestions about multivariate case:\n\n5. Are you certain that BivariateFit and ANM are the only models that you should be comparing against for this multivariate setting?\n\n6. What is CGNN\u2019s runtime? Would you be able to compare against CGNN in time for a potential camera-ready version of this paper?", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}