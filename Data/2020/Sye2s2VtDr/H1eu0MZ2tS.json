{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I made a quick assessment of this paper.", "title": "Official Blind Review #3", "review": "In the paper, the authors proposed CrossGO, an algorithm for finding crossing features useful for prediction.\nIn CrossGO, one trains a neural network that captures feature crossing implicitly.\nThen, possible crossing features are estimated using the gradient-based saliency.\nThe idea here is that, if a feature has a crossing with some other features, its contribution in the saliency can vary across different inputs.\nThus, by looking at the variation of the saliency, one can find candidates features for feature crossing.\nCrossGO greedily selects candidate crossings based on the idea above.\nIn the last step, a simple logistic regression is trained using the candidate crossings, and the effective crossings are selected using a forward greedy feature selection.\n\nI found the paper well-written and the idea is easy to follow.\nMy concern, however, is the lack of Factorization Machines (FM) in the experiments.\nIn Introduction, the authors mention to the deep version of FM and stated \"(deep FMs are) not able to generate interpretable cross features\".\nBut, as the authors are aware of, non-deep FMs are able to handle feature crossings in a interpretable way.\nThus, it would be essential to adopt non-deep FMs as the baseline in the experiments.\nBecause the important baseline is missing, I found the results are not convincing enough to claim the effectiveness of the proposed method.\n\n\n### Updated after author response ###\nThe authors have partially addressed my concern by adding FM/HOFMs as the experiment baselines, which I greatly appreciate.\nHowever, I found the current paper misses some other possible baselines for high-order interaction models [Ref1,2].\nAs the authors mentioned in the response, FMs find the feature crossing as a kind of embedded representations, which may not be suitable for modeling sparse interactions.\nThus, the sparse interaction models need to be taken into consideration as well.\n\n[Ref1] Safe Feature Pruning for Sparse High-Order Interaction Models\n[Ref2] Selective Inference for Sparse High-Order Interaction Models", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}