{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #7", "review": "This paper proposes a method to capture patterns of \u201coff\u201d neurons using a newly proposed metric. While the authors have considered only linear networks, the setup is still relevant because how often these networks can give meaningful results, and can possibly pave the way for future research into more general networks. \n\nPros: The idea itself is interesting, the related works are discussed well, and MNIST experiments are very interesting. \n\nCons/comments : The writing needs a lot of improvement if to be considered for a top venue like iclr.  Other than the MNIST experiments, which show and indicate the importance of relative contrast and boundary, I am not sure how other experiments are meaningful. CIFAR and smallnorb experiments are merely presented, without discussions on what the interpretation shows or helps over the existing methods. Infact, the other methods seem to capture a lot more information than the proposed method. I would suggest adding more discussions and more experiments that show interpretation that this method/metric helps with to make this work stronger.\n\nHave the authors considered  the metric to consider \u201con\u201d neurons instead of \u201coff\u201dneurons ? Is it possible to have a general metric that combines the two in some way ? Intuitively, its unclear to me why only the off patterns can help (except in specific cases as shown in MNIST experiments). \n\n \u201cand thus is responsible for the activity vi\u201d \u2013 This is unclear to me. I understand the projection part though, but I cant make sense of this statement.\n\n\u201cinterpretation and interpretability \u201d in the introduction \u2013 the writing is too informal. Making use of italicized phrases like \u201cswitched linear projection\u201d does not help with the understanding at all, especially because \u201cswitched\u201d is defined after using the term atleast thrice. \n\nConfirmation bias <-> \u201cinformation we want to get\u201d. \n\nThe same issue right after eq 6. \u201cReference subtracted from \u2026.\u201d where the first word is italicized to probably imply some intuitive explanation, but for someone not familiar with what reference is just tends to confuse the reader.  \nPlease fix missing references.\n\nEq 7 seems written incorrectly, with the where \u201cv= \u2026\u201d. Please fix. \n\nWhat is the variance of saliency checks ? In other words, if the experiment of 100 random samples is repeated (say) 20 times, how different are the corresponding coefficients across these repeated runs ?\n\nFigure 3 is waste of space (move to appendix?)\n\nI might be splitting the hairs but Theorem 1 does not warrant a theorem. The result/proof is too straightforward to be a theorem and is already known in some form in the folklore. \n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}