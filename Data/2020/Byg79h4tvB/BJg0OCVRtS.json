{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "Summary:\n- key problem: address \"class mismatch\" in adversarial learning methods for unsupervised domain adaptation (UDA);\n- contributions: 1) extension of the domain adversarial learning objective to leverage class prototypes (exponential moving average of features weighted by predicted class probabilities) in addition to pseudo-labels and intermediate representations (cf. eqs.5-11), 2) state-of-the-art results on several UDA tasks (Office-Home, ImageCLEF-DA, sim2real on Cityscapes).\n\nRecommendation: weak accept (with some reservations below).\n\nKey reason: interesting and effective use of prototypes for UDA.\n- The formulation of the prototypes and additional learning objectives for UDA are clear and seem novel, although I would like to see a discussion of additional related works:\n-- \"Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results\", Tarvainen and Valpola, NeurIPS'17;\n-- \"Unsupervised Domain Adaptation with Similarity Learning\", Pinheiro, CVPR'18;\n-- \"Transferable Prototypical Networks for Unsupervised Domain Adaptation\", Pan et al, CVPR'19.\n- The effectiveness of the contributions is validated on multiple UDA tasks, and the ablative analysis supports the claims (that prototype-level alignment and within-class compactness helps).\n\nMain reservation: the specific problem is not clearly formalized.\n- What is the often mentioned but not clearly described \"class mismatch\" problem in UDA? To the best of my knowledge, this not a standard problem (could not find any mention in the previous literature, no citations or definitions in the submission). Is it that the target label space is different than the source label space (e.g., different ontologies)? In this case, what is the information on the target label space that enables unsupervised adaptation from the source one? What is the inductive bias / prior / assumptions? \n- Alternatively, is the tackled problem only the noise in the pseudo-labels?\n- In any case, the submission would greatly benefit from a clearer mathematical formalism and experimental characterization of the specific problem tackled here, especially in light of claims like \"conditioning the alignment on pseudo labels can not well address the mismatch problem. Compared with the pseudo labels, the class prototypes are more robust and reliable in terms of representing the distribution of different semantic classes.\"\n\nAdditional Feedback:\n- missing references on sim2real UDA: \"DADA: Depth-aware Domain Adaptation in Semantic Segmentation\" (Vu et al, ICCV'19), \"SPIGAN: Privileged Adversarial Learning from Simulation\" (Lee et al, ICLR'19)\n\n## Post rebuttal update\n\nI would like to thank the authors for replying to our questions. The clarifications with respect to related works and missing references is helpful, although a bit high-level (i.e. not necessarily describing the relative advantages of the proposed method). Nonetheless, the expected benefits of prototypes is still not entirely clear enough here, for instance regarding the main statistical assumptions that the method needs to make to get robust prototypes (e.g., in the presence of outliers or specific forms of \"inaccuracies\" in the pseudo-labels or \"domain misalignment\"). Therefore, due to the overall lack of mathematical clarity in the text and rebuttal, my main reservation remains, and I will change my \"weak accept / borderline\" score to weak reject. I encourage the authors to formalize the problem in a clearer, non-ambiguous way, discussing more explicitly the limitations of the proposed method.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}