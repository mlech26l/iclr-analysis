{"experience_assessment": "I have read many papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #4", "review": "The authors consider energy-based learning for discriminating real vs machine generated text. They explore the approach of using a generative text model to generate machine generated training examples. They then consider generalization when the generative model in test time is different from the generative model used for training, as well as if the training data changes to a different corpus. They observe that their model is reasonably able to generalize when the generative model or training data is changed.\n\nThe experiments in this work seem fine. My main issue is with the theory, specifically if their approach to using an energy function is truly different from supervised learning. \n\nIt is not really clear why an energy model is useful for the tasks they consider in the paper, as it essentially seems to be a binary classification problem. Additionally, is it fair to say that the BCE loss used is essentially the classic supervised loss function, modulo using the most offending negative? If we model the probability the text is real as exp(-E(x)) / (exp(-E(x)) + 1), then we get the classic supervised loss function (again modulo using the most offending negative).\n\nTo me, an energy based approach would be to model P(x) = exp(-E(x)) / Z, where Z is a normalization constant. I would calculate the log likelihood as -E(x) - log(Z), which agrees with LeCun, 2006 and Du and Mordatch, 2019.\n\nThe authors need to do a better job explaining why they consider this an energy based approach and relate it to more typical energy based approaches. Additionally, a bit of text describing why using the most offending negative would be helpful.\n\nAn additional experiment that would be interesting is to train the model using many different generative text models and test on an unused generative text model.\n\nI would also like to see a more formal definition of \"residual\". \n\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}