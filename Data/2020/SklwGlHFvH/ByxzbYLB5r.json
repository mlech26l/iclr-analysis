{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "This paper used the field-theory formalism to derive two approximation formulas to the expected generalization error of kernel methods with n samples. Experiments showed that the sub-leading approximation formula approximates the generalization error well when $n$ is large. \n\n\nThis paper is poorly written. Many mathematic notations and terminologies are not well-defined. The setup of the experiments are not given clearly. Here I gave some examples: \n1) The authors claimed that they derived two approximation formulas, EK and SL. I didn't find a clear statement in the main text saying which formula is the EK approximation and which formula is the SL approximation. My conjecture is that, Eq. (10) gives the EK formula, and SL formula is not given in the main text. In addition, Eq. (10) is confusing because the authors wrote that Eq. (10) is a simplification of Eq. (8). However, Eq. (8) was an approximate equality, then Eq. (10) turned into an equality. \n2) Figure 1 gives experimental results. However, the description of the experimental setup is completely vague. The authors described the kernel and the target function as \"the NTK kernel implied by a fully connected network of depth 4 with $\u03c3_w^2 = \u03c3_b^2 = 1$ and ReLU activations\" and \"a target function with equal spectral weights at $l = 1, 2$\", without other explanations. I don't think readers can figure out what is exactly the kernel and the target function from this description. \n3) I am concerned about the writing style of this paper. I am OK with the physics jargon the authors used in the paper, as well as the non-rigorous of the result. But I think the authors should write equations in a clear way. For example, the definition of renormalized NTK should better be defined in equations such as $K_r(x, x') = \\sum_{k = 0}^r b_k <x, x'>^k$, rather than be described in words like \"trim after the r\u2019th power\". \n\n\nHere is a technical question: \n- It seems that the authors claimed that both EK and SL give approximation error O(1/N^3). Then why SL is the \"sub-leading asymptotics\"? \n\n\nI feel the content of the paper is somewhat interesting. However, the paper is poorly written. The authors failed to deliver effective scientific communication to the readers. The results cannot be reproduced after reading this paper. Therefore, I would give a clear reject. \n\n\n---------\nAfter reading the response and the revised paper: \n\nI found that the authors modified and improved their manuscript a lot. They made much effort to address the issues I raised. This is why I think I can potentially raise my score to a weak rejection. \n\nHowever, the modifications made by the authors are still not sufficient. For example, I asked the authors in my review to clarify what is the target function for the experiments. The authors now write in the paper \"We consider input data in dimension d = 50 and a scalar target function $g(x) = \\sum_{l=1,2;m} g_{lm}Y_{lm}(x)$ such that $\\sum_{l=1, m} g_{lm}^2 = \\sum_{l=2, m} g_{lm}^2 = 1/2$, but otherwise iid $g_{lm}$\u2019s.\" I believe that a (random) target function that satisfies all these conditions doesn't exists. I guess what the authors want to say is something like \"taking $g(x) = \\sum_{l=1, 2} \\sum_{m = 1}^{M_l} g_{lm}Y_{lm}(x)$, $(g_{11}, ..., g_{1 M_1}) \\sim Unif(S^{M_1 - 1}(1/\\sqrt 2))$, and $(g_{21}, ..., g_{2 M_2}) \\sim Unif(S^{M_2 - 1}(1/\\sqrt 2))$\". The problem of the statement of the authors is that, if $\\sum_{m=1}^{M_1} g_{1m}^2 =\\sum_{m = 1}^{M_2} g_{2m}^2 = 1/2$, $(g_{lm})_{l = 1, 2; m \\in \\{1, \\ldots, M_l \\}}$ cannot be i.i.d. (one choice is to make $g_{11} = ... = g_{1M_1} = \\sqrt{1/(2 M_1)}$ and $g_{21} = ... = g_{2 M_2} = \\sqrt{1/(2 M_2)}$ be deterministic, but they are unequal). This is just an example of the writing problem of the paper. There are many other issues. \n\nI doubt this paper can be easily accepted at a Physics venue. I used physics tools like replica methods and I knew some Physicists published in machine learning conferences. The papers these Physicists wrote deliver clear scientific communications, though also using jargons and non-rigorous tools. There are many papers using physics tools studying machine learning problems, which published at ML conferences like ICLR, ICML, and NeurIPS. This paper is far less as accessible as those papers. \n\nFinally, I want to point out that, the generalization of kernel methods have been intensively studied in the machine learning literature, for example using the RKHS theory. It would be nice to cite related literature and compare the results. It is my fault that I didn't bring this point up in my review. \n\nI agree that there could potentially be great ideas in this paper. The conference is a venue with quality control. I encourage the authors to submit this paper again after they make more efforts to improve its accessibility. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}