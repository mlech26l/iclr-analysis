{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #1", "review": "Motivated by the observation that powerful deep autoregressive models such as PixelCNNs lack the ability to produce semantically meaningful latent embeddings and generate visually appealing interpolated images by latent representation manipulations, this paper proposes using Fisher scores projected to a reasonably low-dimensional space as latent embeddings for image manipulations. A decoder based on a CNN, a Conditional RealNVP, or a Conditional Pyramid PixelCNN is used to decode high-dimensional images from these projected Fisher score.  Experiments with different autoregressive and decoder architectures are conducted on MNIST and CelebA datasets are conducted. \n\nPros:\n\nThis paper is well-written overall and the method is clearly presented.\n\n\nCons:\n\n1) It is well-known that the latent activations of deep autoregressive models don\u2019t contain much semantically meaningful information. It is very obvious that either a CNN decoder, a conditional RealNVP decoder, or a conditional Pyramid PixelCNN decoder conditioned on projected Fisher scores will produce better images because the Fisher scores simply contain much more information about the images than the latent activations. When the $\\alpha$ is small, the learned decoder will function similarly to the original pixelCNN, therefore, latent activations produce smaller FID scores than projected Fisher scores for small $\\alpha$\u2019s. These results are not surprising. Detailed explanations should be added here.\n\n2) The comparisons to baselines are unfair. As mentioned in 1), it\u2019s obvious that Fisher scores contain more information than latent activations for deep autoregressive models and are better suited for manipulations. Fair comparisons should be performed against other latent variable models such as flow models and VAEs with more interesting tasks, which will make the paper much stronger.\n\n3) In Figure 3, how is the reconstruction error calculated? It\u2019s squared error per pixel per image?\n\n4) On pp. 8, for semantic manipulations, some quantitative evaluations will strengthen this part.\n\nIn summary, this paper proposes a novel method based on projected Fisher scores for performing semantically meaningful image manipulations under the framework of deep autoregressive models. However, the experiments are not well-designed and the results are unconvincing. I like the idea proposed in the paper and strongly encourage the authors to seriously address the raised questions regarding experiments and comparisons.\n\n------------------\nAfter Rebuttal:\n\nI took back what I said. It's not that obvious that the \"latent activations of deep autoregressive models don\u2019t contain much semantically meaningful information\". But the latent activations are indeed a weak baseline considering that PixelCNN is so powerful a generator. If the autoregressive generator is powerful enough, the latent activations can theoretically encode nothing.  I have spent a lot of time reviewing this paper and related papers, the technical explanation about the hidden activation calculation of PixelCNN  used in this paper is unclear and lacking (please use equations not just words). \n\nRelated paper:  The PixelVAE paper ( https://openreview.net/pdf?id=BJKYvt5lg ) explains that PixelCNN doesn't learn a good hidden representation for downstream tasks\n\nAnother paper combining VAE and PixelCNN also mentions this point:\n\nECML 2018: http://www.ecmlpkdd2018.org/wp-content/uploads/2018/09/455.pdf\n\nPlease also check the related arguments about PixcelCNN (and the \"Unconditional Decoder\" results) in Variational Lossy Autoencoder (https://arxiv.org/pdf/1611.02731.pdf )\n\nAs I mentioned in the response to the authors' rebuttal, training a separate powerful conditional generative model from some useful condition information (Fisher scores) is feasible to capture the global information in the condition, which is obvious to me. This separate powerful decoder has nothing to do with PixelCNN, which is the major reason that I vote reject.\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}