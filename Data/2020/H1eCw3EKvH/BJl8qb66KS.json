{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #3", "review": "This work carefully studies RL for neural machine translation and draws several conclusions:\n1. One of the most common RL methods for MT does not optimize the expected reward, as well as show that other methods take an infeasibly long time to converge. \n2. RL practices in MT are likely to improve performance only where the pre-trained parameters are already close to\nyielding the correct translation. \n3. Observed gains may be due to effects unrelated to the training signal, concretely, changes in the shape of the distribution curve.\n\nI have questions about several technical claims, which lead to my doubt about the technical correctness of the paper:\n\n\t1. [updated after checking authors' response] \"it may well converge to values that are not local maxima of R, making it theoretically ill-founded.\" Previously I had concerns about the convergence of REINFORCE with deep NNs as its policy. After checking the references provided by the authors, the local convergence can indeed be guaranteed.  \n \n\t2. \"reducing a constant baseline from r, so as to make the expected reward zero, disallows learning.\" This conflicts with my intuition. Where is the experiment supporting this claim?\n\n\t3. \"MRT succeeds in pushing ybest to be the highest ranked token if it was initially second, but struggles where it was initially ranked third or below.\" Why ybest in third position cannot be boosted while second can be boosted? Figure 5 only shows two tokens, which cannot lead to any meaningful statistical conclusions. I'd like to see the statistic numbers: \n\t\ta. how many ybest in second are boosted to first in training? How many are not?\n\t\tb. how many ybest in third are boosted to first or second in training? How many are not?\nHow about other positions?", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}