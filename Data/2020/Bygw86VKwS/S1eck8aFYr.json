{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "N/A", "review_assessment:_thoroughness_in_paper_reading": "N/A", "title": "Official Blind Review #2", "review": "This paper studies the problem of learning RL agents that are robust to adversarial episode termination. The paper casts this problem as a two-player, zero-sum game between a policy player, which takes actions in the environment, and a termination player, which chooses when the episode should terminate. The paper develops some theory surrounding this problem, showing that the game has a well defined value, the Bellman operator continues to be a contraction, and the optimal policy for the termination player is well defined. The paper then proposes an algorithm for approximately finding the optimal policy.\n\nI am leaning towards rejecting the paper, primarily because it is unclear whether the proposed algorithm actually works. I would consider increasing my score if the paper were revised to include experiments showing that the proposed algorithm does, indeed, find the optimal fault-tolerant policy, and does so better than naive baselines (e.g., training with an environment that terminates uniformly at random).\n\nI am not an expert in stochastic games and stopping games, so it is not immediately obvious to me how significant the theoretical results are. For example, why does the existence of a Nash equilibrium not follow immediately from the Nash existence theorem?\n\nMinor points:\n* The large number of abbreviations (SG, OSP, FT, SPE, BR) make the paper a bit hard to read. Since most are only used a handful of times, I'd recommend spelling each out.\n* \"optimal stochastic control\" -- I think that \"stochastic optimal control\" is slightly more standard wording.\n* \"and \\gamma is a discount factor\" -- One of the square brackets is backwards.\n* \"is initialised with weight vector\u2026\" -- What does r_0(P) mean? (Isn't P the dynamics of the MDP?)\n* \"Enhancing R&D\u2026\" -- This citation is repeated in the bibliography.\n\n--------------------- UPDATE AFTER (NO) AUTHOR RESPONSE ----------------------\nSince the authors did not post a response, I maintain my vote to \"weak reject\" this paper. I do think that the problem considered is interesting, and would encourage the authors to (1) clarify how the theory differs from prior work and (2) run experiments to empirically validate the algorithm. If these were done, I think the paper would make a strong submission to a future conference.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}