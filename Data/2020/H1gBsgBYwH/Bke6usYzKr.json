{"experience_assessment": "I do not know much about this area.", "rating": "8: Accept", "review_assessment:_checking_correctness_of_experiments": "I did not assess the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "The authors study the generalization error of two-layer neural nets, where an asymptotic point of view is taken. Their main results can be summarized as follows.\n1. If only the second layer is optimized, they observe the double-descent phenomenon.\n2. However, if only the first layer is optimized, the double-descent is not observed.\nThis shows that recent results for certain linear models (e.g. Song, Montanari 2019) do not directly transfer to neural networks. As the authors point out, however, if a different scaling is used in the asymptotics, double descent might still be observed.\n\nI see the following strengths of the paper. \n-This is a very well-written paper with a clear message.\n-The result is important and gives new insights into the generalization properties of neural networks.\n\nIn my view, this is an interesting contribution, which should be accepted. \n\n---------\n\nThank you for your response. I will leave the rating unchanged.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}