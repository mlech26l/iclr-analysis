{"experience_assessment": "I do not know much about this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "This paper introduces a transformation from the deep image prior (DIP) to an embedding with an autoencoder (MMES). The authors aim to use this transformation to explain (\"in words\") why the DIP works so well and explain why convolutions are needed in the DIP. The contributions are summarised as a) providing an interpretable analogue to the convnet, b) demonstration of the proposed method's effectiveness, and c) characterisation of the DIP as a \"low-dimensional patch-manifold prior\".\n\nI think the MMES approach is interesting and potentially a good analogue to the DIP, and explicitly draws out the locality prior the authors claim is integral to DIP. The good results and comparison to DIP demonstrates that this locality prior may be important to the task.\n\nI disagree that this method is \"interpretable\"/\"explainable\", at least without any evidence toward this presented in the paper. There is still fundamentally a deep network as in DIP. The discussion on interpretability is limited and mostly provided through comparison with other methods.\n\nAll up I think this is a useful paper, even though the paper overstates its contributions. I would like to see the clarity improved: it took me a long while to make the connection between the method presented in the paper and the implications for DIP. This connection should have been more explicit in the paper. I would also like to see the \"interpretability\" statement either clearly explained or removed (I am not convinced that this method is interpretable).", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}