{"experience_assessment": "I have published one or two papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #4", "review": "After rebuttal,\n\nI think the authors made a valid argument to address my concerns on evaluation. So, I'd like to increase my score as weak accept! \n\n=====\n\n\nSummary:\n\nTo handle noisy labels, this paper proposed a curriculum loss that corresponds to the upper bound of 0-1 loss. Using synthetic noisy labels on MNIST and CIFAR, the authors verified that the proposed method can significantly improve the robustness against noisy labels.\n\nDetailed comments:\n\nOverall, the paper is well-written and the ideas are novel. However, experiments are a little weak due to weak baselines and experimental setups (see suggestions for more details). I will consider raising my score according to the rebuttal.\n\nSuggestions:\n\n1. Could the authors consider more baselines like D2L [Ma' 18] and Reweight [Ren' 18] \n\n2. Similar to [Lee' 19], could the authors evaluate the performance of the proposed methods on more realistic noisy labels such as semantic noisy labels and open-set noisy labels? \n\n[Lee' 19] robust inference via generative classifiers for handling noisy labels, In ICML, 2019.\n\n[Ma' 18] Dimensionality-Driven Learning with Noisy Labels, In ICML, 2018.\n\n[Ren' 18] Learning to Reweight Examples for Robust Deep Learning, In ICML, 2018.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I did not assess the derivations or theory."}