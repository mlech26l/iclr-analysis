{"experience_assessment": "I have published in this field for several years.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #1", "review": "This paper describes \"AlgoNets\", which are differentiable implementations of classical algorithms. Several AlgoNets are described, including multiplication algorithm implemented in the WHILE programming language, smooth sorting, a smooth while loop, smooth finite differences and a softmedian.\n\nThe paper additionally presents RANs (similar to GANs but with an AlgoNet embedded) and Forward AlgoNets (where the the AlgoNet is embedded in a feedforward net). \n\nThe smooth implementations normally amount to replacing hard functions with soft equivalents, for example \"if\" conditions are replaced by logistic sigmoids.\n\nThe research direction in this paper is very interesting and could lead to important advancements, however a strong argument needs to be presented to the readers about why this way of making algorithms smooth is better than other published or obvious techniques.\n\nThe argument could be theoretical, proving for example faster convergence under certain assumptions, or it could be empirical, showing that the method achieves better results than other techniques on some benchmarks. I could not see however any such arguments in this paper.", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}