{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #4", "review": "\n\nThe paper contains one main contribution, the unbiased version of MINE obtained using the eta-trick, however a lot of theory is presented and not always very clearly. While some results are interesting (like the constrained ratio estimation interpretation of the dual) some parts are unclear and of lesser relevance. The section on \u201cWhat Do Neural Estimators of LK or MI Learn\u201d is a collection of different remarks without much coherence, some of which are imprecisely stated. The comparison with the estimator from Pool et al. (2019) could also be much simplified, in particular I would review the list of remarks below theorem 2.\n\nAnother weakness of the paper is that two important aspects in assessing the quality of an estimator are overlooked:  the variance of the estimator and the performance on finite data. Bias is not the only property which matters, both the variance and the dependence on the number of samples should be assessed experimentally, especially when no discussion or theoretical results are provided.  \n\nI liked to see experiments performed on different tasks and datasets but overall that section could be significantly improved. \n\nThe experiment comparing different MI estimators on synthetic Gaussian data is interesting. The plots are however difficult to read, it would be good to make them larger or split the results in different panels. For the 2D and the 20D case, the results reported in the MINE paper are much closer to the true MI than what is reported here, could the authors explain this difference? It would also be good to see some experiments done with a higher ground truth MI, 3.5 is not a lot for higher dimensional cases.\n\nConcerning the Deep InfoMax experiment, we see some improvements when using the proposed MI estimator with Deep InfoMax, however I doubt that this task is an ideal test case for an MI estimator since it has been shown (On Mutual Information Maximization for Representation Learning, Tschannen et al.) that the performance on downstream supervised tasks often does not clearly depend on the quality of MI estimation. \n\n\nSome additional points:\n\nAssuming a finite dimensional feature map in section 3 actually is a loss of generality. \n\nThe proof of lemma 3 is  hard to follow with some notations used without being properly introduced or changed in unexpected ways (eta switches places in f_b(w, eta), what does q do here?, what does PSD mean?). \n\nThe proof of theorem 1 is again unclear. It starts with a typo in the second line (E_y~Q should be replaced by an integral). A couple of lines below a function alpha is introduced without further explanation. \n\nTypos:\n\nThere is one x missing in the proof of Lemma 1 Appendix A.\n\n\n\n\n\n", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}