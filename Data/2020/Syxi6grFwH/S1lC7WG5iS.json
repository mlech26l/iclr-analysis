{"experience_assessment": "I have published one or two papers in this area.", "rating": "1: Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #4", "review": "This work sits at the intersection between neuroscience and machine learning. It proposes to use neural recordings from the rodent hippocampus to shed light into how biological agents achieve continual learning. The approach involves (i) analyzing neural data from the rodent hippocampus with the goal of identifying how neurons encode various behavioral variables; (ii) training different RL agents to solve a computer version of the same task, including tabular and DQN agents; (iii) contrasting the performance and representations of the artificial agents with those of animals.\n\nThe paper has an admirable goal: to find links between neuroscience and machine learning, using tools from one to promote advances in the other. When done correctly, this interaction can be fruitful and produce incredible insights for both fields. However, I believe that this paper does not deliver on either end due to major methodological and analytical flaws, rendering it innapropriate for ICLR. Below I list my major critiques:\n\n1. The interpretations of the dPCA components seems very preliminary and lacks methological rigor. In particular, many alternative interpretations of the components are possible. For instance: Component #3 might represent outcome (rather than decision); Component #4 might represent greater engagement of the hippocampus in the egocentric task (e.g. Packard and McGaugh, 1996); etc. Moreover, the reported analyses do not include animal position, which will almost certainly be a major driver of population activity in the hippocampus (see work on place cells). Since the animal position is not reported, it is impossible to know if the dPCA components (e.g. Component #2) are, instead, representing alocentric position. Including animal position (perhaps also as an explanatory variable in the dPCA) might help, but the authors should also do a more thorough job testing their specific hypotheses beyond simply reporting them based on visual inspection.\n\n2. The comparison between early and later training sessions is also rather crude and qualitative. The authors makes several claims about differences that are not tested directly with a proper hypothesis test.\n\n3. The comparison between RL quantities and dPCA component is also very weak. For instance, the claim that a given dPCA component represents an eligibility trace needs much more evidence than simply showing that this component decays over space when the eligibility trace also decays. With respect to Component #4 (a critical component presumably related to the authors' hypothesis of multi-task representation), the authors report that, for an e-greedy agent, the average value is higher for alocentric vs. egocentric task. Yet, this difference is not investigated further and, again the authors claim victory based on a simple visual comparison between two plots (4C vs. 4D). \n\n4. For most of the paper, the authors report the results from a single (typical?) animal. Ideally, the results for all animals would be reported (or some statistically sound aggregate of all animals).\n\n5. Finally, the authors compare the performance of animal 3 with the performance of different RL agents. Again, this comparison is incredibly superficial and neglects many confound variables. The fact that the accuracy of both the animal and DQN is around 70% is not sufficient to claim that DQN is a good model for the animal's behavior, or that it is superior to other models that achieve slightly worse or better performance. Much more work needs to be done to properly compare RL and animals (e.g. comparing, in addition to performance, representations across various layers, prediction error signals, reward signals, etc). \n\nOverall, while I commend the authors for an intriguing idea, the execution of the idea is so poor that I consider the paper to be of little interest to either the neuroscience or the machine learning communities. Therefore, I cannot recommend the paper for publication at ICLR.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}