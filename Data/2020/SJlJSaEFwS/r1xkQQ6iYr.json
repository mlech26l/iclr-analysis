{"experience_assessment": "I have published in this field for several years.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "N/A", "title": "Official Blind Review #2", "review": "\n***Update***\n\nI thank the reviewers for answering my questions, and I have read the reviews from the other reviewers.  I am borderline on this paper, but still learn towards rejection. I feel that it is a bit incremental and still a little misleading/over-stated. For instance, xnli isn't mentioned but mldoc is, it isn't clear in the table which methods are mappings and which aren't (big data difference), in the mldoc experiment was more parallel data used for these specific languages than was used for LASER? the experiment I asked for wasn't done on the same corpora head-to-head with LASER and their approach. I think any claims about outperforming LASER need to be evaluated on the same corpus as much as possible (Europarl) and weaknesses of the approach should also be mentioned (it is not multilingual in these evaluations). Otherwise you conflate data/multilingualness/model which makes it hard to draw conclusions from the experiments. Also CSLS  was not applied to the ACL paper and this makes a huge difference and should be accounted for (and also idf possibly). Also this paper still isn't at least mentioned which is very related in my opinion.\n\nThis paper proposes a method to learn bilingual word embeddings by modifying the Sent2Vec (which is based on word2vec) approach, and applying it to bitext. They evaluate on monolingual and bilingual word similarity, bitext mining, and a zero-shot document classification task where a classifier is trained on data in one language but evaluated on another (using their embeddings as features in both cases).\n\nI have the following concerns about this paper:\n\n1) For the sentence mining tasks - how come Ormazabal 2019 is not included? The baselines are weak and the task is not standard. One of the baselines used here is MUSE which is unsupervised (The refined version of MUSE was also not included in these experiments). There are fixed datasets that people have experimented with (like BUCC) that would help tie in your results here with the literature a little better. These could include LASER (which is already compared to for document classification) and \"Simple and Effective Paraphrastic Similarity from Parallel Translations\" ACL 2019, which like this paper, proposes a pooled token embedding approach and outperforms more complicated architectures. Neither of these approaches uses idf either (how much does idf help - is it really needed?).\n\n2) For the zero-shot document classification task, it should also be pointed out that LASER can handle many languages all at once. Can this approach also work well if all languages were trained jointly?. Also did you evaluate on XNLI for zero-shot as well? LASER does very well here. I do realize comparing to LASER is not really fair since it is trained on so much data, however the model is similar to previous versions of LASER that were trained on Europarl, which could also be used as the data for training your models for a more apples-to-apples comparison.\n\n3) Note that also the improvements on monolingual similarity using parallel data are well known. For instance \"Embedding Word Similarity with Neural Machine Translation\" (arXiv 2014).. Also even the base for the current state of the art models on SimLex-999, Paragram (TACL 2015), used paraphrases created by pivoting on parallel data.\n\nI think the main contributions of this paper are modifying Sent2vec so it can be used on bilingual data and using it to learn nice representations for words and sentences (and documents). I think that to be published, it should clearly outperform and/or have advantages over all previous works - and this is not clear from this paper in its current form. It is okay if it doesn't do the best on everything, but it is hard to tell how this work currently fits into the literature especially in terms of the sentence-level tasks which are a focus.", "review_assessment:_checking_correctness_of_derivations_and_theory": "N/A"}