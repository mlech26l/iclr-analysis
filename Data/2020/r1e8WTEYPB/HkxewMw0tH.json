{"experience_assessment": "I have published one or two papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper at least twice and used my best judgement in assessing the paper.", "title": "Official Blind Review #2", "review": "This paper studies the problem of applying attention to the problem of image captioning. To this end the authors first apply full attention where the probabilities are computed using softmax before applying the recently proposed Sparsemax - which essentially computes probabilities from scores by performing a projection on to the probability simplex. The authors then propose a variant of Sparsemax which they call TVMax, which has the property that it encourages assigning probability weights to contiguous regions in 2D space unlike Sparsemax which has no such incentive. The main idea is to augment the Sparsemax projection loss with a Lasso like penalty which penalizes assigning different attention probabilities to contiguous regions in the image. The authors then compare their TVMax approach with softmax and Sparsemax attention for image captioning and show improvements on the MSCOCO and Flickr datasets.\n\nThe idea of applying additional structural constraints on the sparsity structure induced by Sparsemax is a cool idea, and I like the idea of incentivizing contiguous pixels to have similar attention probabilities. Sparse attention patterns seems like an important direction of research with the motivation of either 1) improving generalization over full attention or 2) scaling to inputs of length where full attention is not feasible. This seems like a good progress in the first direction. The major weakness I see in this work is that the authors only limited their experiments to image captioning. It would be interesting to see if their approach could benefit other tasks such as machine translation, image generation etc. The other issue with their approach is that it doesn't seem to scale well - if I understand correctly their algorithm takes O(n^2logn) for sequence length n. The other issue potentially could be weak baselines since the authors use an LSTM for their caption generation network instead of Transformer.\n\n[Edit: After going through reviewer discussion, I updated my score to reject. I am not convinced of the motivation for sparse attention unless it is for long sequences, since otherwise the regular softmax should be able to assign 0's to the un-needed items. Moreover, for generalization one can use attention dropout which is simpler instead.]", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}