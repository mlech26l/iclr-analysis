{"experience_assessment": "I have read many papers in this area.", "rating": "3: Weak Reject", "review_assessment:_checking_correctness_of_experiments": "I carefully checked the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #4", "review": "The paper presents an approach to create unsupervised representations of remote sensing images. The essential idea is to enforce similarity between representations of multiple views obtained by subsetting channels from multiple co-terminus sensor outputs.  This is implemented by training with the InfoNCE loss on high-level features (last two layers of a ResNet 50) of two views of the same image and multiple view of other images which are passed through the same weight-shared network. The evaluation is based on a custom task of classifying OSM labels. The results show that (a) the learned representation (up to 3 chosen channels) outperform a pre-trained ImageNet fine-tuned for the classification task, (b) multiple low resolution sensors can outperform a higher resolution sensor, and (c) visualisation of images indicates that stable high-level representations across sensors. \n\nThe paper makes a worthwhile contribution in introducing contrastive methods to satellite imagery - a domain well suited for analysing how contrastive methods work and also rich in applications of sensor fusion/augmentation for remote sensing applications. The experiments indicate that this is a promising direction, and the authors have helpfully open-sourced the dataset they used. The paper, however, is short on several accounts. Primarily, the experimental evaluation is sparse in detail and rigour. In addition, the paper makes unsubstantiated claims to \u201cargue out\u201d certain baselines from being compared. Finally, the results indicate modest improvements on a custom task, and thus remain inconclusive. \n\nThe paper bases all experimental evaluation and conclusions thereof on the custom task of classifying 12 classes of distinctive objects on 8400 images obtained from OpenStreetMap (OSM). These include diverse categories spanning generic bodies (water, forest), specific structures (substation, bridge), similar items (farm, farmland). The paper does not discuss why this is a good task (is it challenging, is it representative of remote sensing applications, are these most frequent OSM classes). Indeed, the experimental results provide no intuition on the classification task (eg. confusion matrix is essential especially given the middling accuracy of about 0.5). \n\nThe paper makes a strong claim that the \u201cdistributional hypothesis\u201d (of expecting that spatial or temporal similarity reflect in representation similarity) does not apply to satellite imagery because \u201cremote sensing imagery \u2026 can change abruptly between adjacent patches\u201d. No evidence is provided of what I believe is an unintuitive claim. Indeed, existing work [1] (as cited in the paper) uses this hypothesis to create representations for satellite images. Glaringly, having made the claim, the paper does not compare proposed approach with the representations computed in [1].  The paper also makes the claim that computing representation loss should be done with high-level features rather than individual pixels. Again, this is not substantiated as the paper does not compare the proposed methods with simple auto-encoder baselines. In the absence of these baselines, the results of this paper on a custom data-set remain inconclusive. \n\nThe evaluation leaves out several other expected experiments. A few suggested conditions for ablation tests are listed:\n(a) Different augmentation across channels\n(b) Different values of \\lambda_L (only an extreme case of last two layers has been presented)\n(c) At least one other CNN-backbone, perhaps a deeper ResNet\n(d) Different orderings of introducing the channels (not only by low or high resolution ordering)\n(e) Different sizes of the tiles for learning representations (curiously the paper does not mention the size of the tiles as used currently)\n\nFinally, and more broadly, the proposed approach aims to compensate the lack of supervised labels by exploiting redundancy across multiple sensors/channels. In the chosen setup, this redundancy is very high as 4 different RGBI co-terminus sensors are chosen, thereby requiring augmenting and drop-out to simulate some variation. A more realistic or challenging setup would be required to evaluate the underlying ideas.\n\n[1] Jean, Neal, et al. \"Tile2Vec: Unsupervised representation learning for spatially distributed data.\" Proceedings of the AAAI Conference on Artificial Intelligence. Vol. 33. 2019.\n\n--\n\nUpdate in response to rebuttal: \nThe authors agreed to most of the points raised, but provided no clear suggestions in addressing them. I re-emphasise that the empirical results on a single custom dataset based on OSM is limited. The author response to this remains vague. Further none of the reasonable baselines have been compared against, a point which the authors ignored in the rebuttal. In light of this, rating remains the same. ", "review_assessment:_checking_correctness_of_derivations_and_theory": "I assessed the sensibility of the derivations and theory."}