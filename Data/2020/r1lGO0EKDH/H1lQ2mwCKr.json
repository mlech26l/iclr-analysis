{"experience_assessment": "I have read many papers in this area.", "rating": "6: Weak Accept", "review_assessment:_checking_correctness_of_experiments": "I assessed the sensibility of the experiments.", "review_assessment:_thoroughness_in_paper_reading": "I read the paper thoroughly.", "title": "Official Blind Review #2", "review": "Summary: The authors propose a way to fuse information on nodes of a graph with the topology of the graph in the large scale setting. The proposed approach is done in four phases where (i) the covariates in the nodes of the graph is first mapped in the graph space for fusion and fused using linear combination of the topological graph and feature graph, (ii) the resulting \"adjacency\" matrix will almost surely not be sparse even if the original graph space, so they use eigenvalues of the graph laplacian to coarsen the graph -- remove edges; (iii) they then propose to embed the coarsened graph using \"any\" unsupervised learning technique; (iv) then the embedded representation is refined using iterative procedures. Cheap procedures are introduced to do Phases (i) and (iv). Experimentally the authors see improvements in the performance using their approach compared to the baselines considered.\n\nNovelty: 1. The approach suggested in this paper is already there in MILE Fig 1., the authors mention that MILE requires training GCN but I am not sure why this is critical. The authors mention that \"MILE cannot support inductive embedding\nmodels due to the transductive property of GCN\", can you clarify what this means? I guess one can easily replace GCNs?\n\n2. Covariate adjusted clustering is known to work only when when the features are independent like Stochastic Block Model, see  Covariate-assisted spectral clustering by Binkiewicz et al, 2014. Is there a reason why the features that we see on nodes are not correlated?\n\nResults: It is hard to see where the performance improvement actually comes from, if at all. It is interesting to see that the proposed approach saves time and is more accurate in the variety of settings considered, but it is not clear why we see the improvement. \n\nAfter rebuttal: I have raised my score to 6 after going through the authors' response for my questions, and other reviewers' concerns. While the approach performs well in many datasets (thanks to the authors for providing more experimental evidence!), I'm still not convinced with the authors' response on their fusion step -- it seems to me that node attributes are \"side\" information, that can \"boost\" the signal on the original neighborhood graph. Recall that spectral approaches do have a fundamental barrier -- they fail on \"thin\" graphs (see https://arxiv.org/abs/1608.04845 ). Hence,  node covariance/fusion matrix being dense will be a blessing for spectral approaches since they make spectral methods work. However, is this what we want in *all* the cases? I'm not sure. This means that the choice of \\beta in their fusion step is *very* important, and I don't see any plots on the sensitivity of their procedure with respect to \\beta. I kindly request the authors to include a plot or results showing the sensitivity of the final results with respect to the choice of \\beta. Thanks!", "review_assessment:_checking_correctness_of_derivations_and_theory": "I carefully checked the derivations and theory."}